{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚òÄÔ∏è Imports and Setup\n",
    "\n",
    "According to the official [Train Custom Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data) guide, YOLOv5 requires a certain directory structure. \n",
    "\n",
    "```\n",
    "/parent_folder\n",
    "    /dataset\n",
    "         /images\n",
    "         /labels\n",
    "    /yolov5\n",
    "```\n",
    "\n",
    "* We thus will create a `/tmp` directory. <br>\n",
    "* Download YOLOv5 repository and pip install the required dependencies. <br>\n",
    "* Install the latest version of W&B and login with your wandb account. You can create your free W&B account [here](https://wandb.ai/site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚Äòtmp‚Äô: File exists\n",
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp\n"
     ]
    }
   ],
   "source": [
    "#make a directory for yolov5\n",
    "!mkdir tmp\n",
    "%cd tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp\n",
      "Setup complete. Using torch 1.9.0+cu102 (TITAN Xp)\n"
     ]
    }
   ],
   "source": [
    "# Download YOLOv5\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "# Install dependencies\n",
    "%pip install -qr requirements.txt  # install dependencies\n",
    "\n",
    "%cd ../\n",
    "import torch\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install W&B \n",
    "!pip install -q --upgrade wandb\n",
    "# Login \n",
    "import os\n",
    "key = os.getenv('WANDB_API_KEY')\n",
    "# print(key)\n",
    "import wandb\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Necessary/extra dependencies. \n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶Ü Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'input/siim-covid19-resized-to-512px-png/train/'\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 200\n",
    "HOME= '~/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection'\n",
    "CLASS_NUMBER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî® Prepare Dataset\n",
    "\n",
    "This is the most important section when it comes to training an object detector with YOLOv5. The directory structure, bounding box format, etc must be in the correct order. This section builds every piece needed to train a YOLOv5 model.\n",
    "\n",
    "I am using [xhlulu's](https://www.kaggle.com/xhlulu) resized dataset. The uploaded 256x256 Kaggle dataset is [here](https://www.kaggle.com/xhlulu/siim-covid19-resized-to-256px-jpg). Find other image resolutions [here](https://www.kaggle.com/c/siim-covid19-detection/discussion/239918).\n",
    "\n",
    "* Create train-validation split. <br>\n",
    "* Create required `/dataset` folder structure and more the images to that folder. <br>\n",
    "* Create `data.yaml` file needed to train the model. <br>\n",
    "* Create bounding box coordinates in the required YOLO format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "                                                path image_level  \n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...        none  \n",
       "2  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "3  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "4  input/siim-covid19-resized-to-512px-png/train/...     opacity  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Everything is done from /kaggle directory.\n",
    "%cd {HOME}\n",
    "\n",
    "# Load image level csv file\n",
    "df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')\n",
    "\n",
    "# Modify values in the id column\n",
    "df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n",
    "# Add absolute path\n",
    "df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n",
    "# Get image level labels\n",
    "df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opacity    4294\n",
       "none       2040\n",
       "Name: image_level, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8ba599611e5</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29b23a11d1e4</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8174f49500a5</td>\n",
       "      <td>2330</td>\n",
       "      <td>2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d54f6204b044</td>\n",
       "      <td>2330</td>\n",
       "      <td>2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d51cadde8626</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47d014f9055a</td>\n",
       "      <td>2991</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89fd7f185d77</td>\n",
       "      <td>3480</td>\n",
       "      <td>4248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7c40e04c6163</td>\n",
       "      <td>2540</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6a93346150a4</td>\n",
       "      <td>2540</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5b687c54d3fd</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  dim0  dim1\n",
       "0  d8ba599611e5  2336  2836\n",
       "1  29b23a11d1e4  3488  4256\n",
       "2  8174f49500a5  2330  2846\n",
       "3  d54f6204b044  2330  2846\n",
       "4  d51cadde8626  3488  4256\n",
       "5  47d014f9055a  2991  2992\n",
       "6  89fd7f185d77  3480  4248\n",
       "7  7c40e04c6163  2540  2880\n",
       "8  6a93346150a4  2540  2880\n",
       "9  5b687c54d3fd  3488  4256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load meta.csv file\n",
    "# Original dimensions are required to scale the bounding box coordinates appropriately.\n",
    "meta_df = pd.read_csv('input/siim-covid19-resized-to-512px-png/meta.csv')\n",
    "train_meta_df = meta_df.loc[meta_df.split == 'train']\n",
    "train_meta_df = train_meta_df.drop('split', axis=1)\n",
    "train_meta_df.columns = ['id', 'dim0', 'dim1']\n",
    "\n",
    "train_meta_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "\n",
       "                                                path image_level  dim0  dim1  \n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  3488  4256  \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...        none  2320  2832  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both the dataframes\n",
    "df = df.merge(train_meta_df, on='id',how=\"left\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçò Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 6334, training images: 5067. validation images: 1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation split.\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.image_level.values)\n",
    "\n",
    "train_df.loc[:, 'split'] = 'train'\n",
    "valid_df.loc[:, 'split'] = 'valid'\n",
    "\n",
    "df = pd.concat([train_df, valid_df]).reset_index(drop=True)\n",
    "print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçö Prepare Required Folder Structure\n",
    "\n",
    "The required folder structure for the dataset directory is: \n",
    "\n",
    "```\n",
    "/parent_folder\n",
    "    /dataset\n",
    "         /images\n",
    "             /train\n",
    "             /val\n",
    "         /labels\n",
    "             /train\n",
    "             /val\n",
    "    /yolov5\n",
    "```\n",
    "\n",
    "Note that I have named the directory `covid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badf2d31cdbd</td>\n",
       "      <td>[{'x': 484.0363, 'y': 955.76643, 'width': 587....</td>\n",
       "      <td>opacity 1 484.0363 955.76643 1071.75999 1657.7...</td>\n",
       "      <td>c508e7ff4063</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d95766f633e</td>\n",
       "      <td>[{'x': 1821.70335, 'y': 880.30619, 'width': 66...</td>\n",
       "      <td>opacity 1 1821.70335 880.30619 2485.89476 1875...</td>\n",
       "      <td>2c78ef584129</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2400</td>\n",
       "      <td>2880</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951ac929b71</td>\n",
       "      <td>[{'x': 409.13877, 'y': 955.27207, 'width': 115...</td>\n",
       "      <td>opacity 1 409.13877 955.27207 1559.23612 3211....</td>\n",
       "      <td>24cd517d2846</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69522a81a9b6</td>\n",
       "      <td>[{'x': 1654.70833, 'y': 1096.9792, 'width': 78...</td>\n",
       "      <td>opacity 1 1654.70833 1096.9792 2434.94161 1975...</td>\n",
       "      <td>b22e2537daa0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2446</td>\n",
       "      <td>2630</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98e895293a8c</td>\n",
       "      <td>[{'x': 2191.62551, 'y': 1077.50003, 'width': 1...</td>\n",
       "      <td>opacity 1 2191.62551 1077.50003 3729.32302 298...</td>\n",
       "      <td>58072ae8b0f0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3480</td>\n",
       "      <td>4240</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  badf2d31cdbd  [{'x': 484.0363, 'y': 955.76643, 'width': 587....   \n",
       "1  8d95766f633e  [{'x': 1821.70335, 'y': 880.30619, 'width': 66...   \n",
       "2  1951ac929b71  [{'x': 409.13877, 'y': 955.27207, 'width': 115...   \n",
       "3  69522a81a9b6  [{'x': 1654.70833, 'y': 1096.9792, 'width': 78...   \n",
       "4  98e895293a8c  [{'x': 2191.62551, 'y': 1077.50003, 'width': 1...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 484.0363 955.76643 1071.75999 1657.7...     c508e7ff4063   \n",
       "1  opacity 1 1821.70335 880.30619 2485.89476 1875...     2c78ef584129   \n",
       "2  opacity 1 409.13877 955.27207 1559.23612 3211....     24cd517d2846   \n",
       "3  opacity 1 1654.70833 1096.9792 2434.94161 1975...     b22e2537daa0   \n",
       "4  opacity 1 2191.62551 1077.50003 3729.32302 298...     58072ae8b0f0   \n",
       "\n",
       "                                                path image_level  dim0  dim1  \\\n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  2336  2836   \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...     opacity  2400  2880   \n",
       "2  input/siim-covid19-resized-to-512px-png/train/...     opacity  3488  4256   \n",
       "3  input/siim-covid19-resized-to-512px-png/train/...     opacity  2446  2630   \n",
       "4  input/siim-covid19-resized-to-512px-png/train/...     opacity  3480  4240   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp/covid/images/train', exist_ok=True)\n",
    "os.makedirs('tmp/covid/images/valid', exist_ok=True)\n",
    "\n",
    "os.makedirs('tmp/covid/labels/train', exist_ok=True)\n",
    "os.makedirs('tmp/covid/labels/valid', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badf2d31cdbd</td>\n",
       "      <td>[{'x': 484.0363, 'y': 955.76643, 'width': 587....</td>\n",
       "      <td>opacity 1 484.0363 955.76643 1071.75999 1657.7...</td>\n",
       "      <td>c508e7ff4063</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d95766f633e</td>\n",
       "      <td>[{'x': 1821.70335, 'y': 880.30619, 'width': 66...</td>\n",
       "      <td>opacity 1 1821.70335 880.30619 2485.89476 1875...</td>\n",
       "      <td>2c78ef584129</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2400</td>\n",
       "      <td>2880</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951ac929b71</td>\n",
       "      <td>[{'x': 409.13877, 'y': 955.27207, 'width': 115...</td>\n",
       "      <td>opacity 1 409.13877 955.27207 1559.23612 3211....</td>\n",
       "      <td>24cd517d2846</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69522a81a9b6</td>\n",
       "      <td>[{'x': 1654.70833, 'y': 1096.9792, 'width': 78...</td>\n",
       "      <td>opacity 1 1654.70833 1096.9792 2434.94161 1975...</td>\n",
       "      <td>b22e2537daa0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2446</td>\n",
       "      <td>2630</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98e895293a8c</td>\n",
       "      <td>[{'x': 2191.62551, 'y': 1077.50003, 'width': 1...</td>\n",
       "      <td>opacity 1 2191.62551 1077.50003 3729.32302 298...</td>\n",
       "      <td>58072ae8b0f0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3480</td>\n",
       "      <td>4240</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  badf2d31cdbd  [{'x': 484.0363, 'y': 955.76643, 'width': 587....   \n",
       "1  8d95766f633e  [{'x': 1821.70335, 'y': 880.30619, 'width': 66...   \n",
       "2  1951ac929b71  [{'x': 409.13877, 'y': 955.27207, 'width': 115...   \n",
       "3  69522a81a9b6  [{'x': 1654.70833, 'y': 1096.9792, 'width': 78...   \n",
       "4  98e895293a8c  [{'x': 2191.62551, 'y': 1077.50003, 'width': 1...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 484.0363 955.76643 1071.75999 1657.7...     c508e7ff4063   \n",
       "1  opacity 1 1821.70335 880.30619 2485.89476 1875...     2c78ef584129   \n",
       "2  opacity 1 409.13877 955.27207 1559.23612 3211....     24cd517d2846   \n",
       "3  opacity 1 1654.70833 1096.9792 2434.94161 1975...     b22e2537daa0   \n",
       "4  opacity 1 2191.62551 1077.50003 3729.32302 298...     58072ae8b0f0   \n",
       "\n",
       "                                                path image_level  dim0  dim1  \\\n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  2336  2836   \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...     opacity  2400  2880   \n",
       "2  input/siim-covid19-resized-to-512px-png/train/...     opacity  3488  4256   \n",
       "3  input/siim-covid19-resized-to-512px-png/train/...     opacity  2446  2630   \n",
       "4  input/siim-covid19-resized-to-512px-png/train/...     opacity  3480  4240   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6334/6334 [00:02<00:00, 2850.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Move the images to relevant split folder.\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    if row.split == 'train':\n",
    "        copyfile(row.path, f'tmp/covid/images/train/{row.id}.png')\n",
    "    else:\n",
    "        copyfile(row.path, f'tmp/covid/images/valid/{row.id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçú Create `.YAML` file\n",
    "\n",
    "The `data.yaml`, is the dataset configuration file that defines \n",
    "\n",
    "1. an \"optional\" download command/URL for auto-downloading, \n",
    "2. a path to a directory of training images (or path to a *.txt file with a list of training images), \n",
    "3. a path to a directory of validation images (or path to a *.txt file with a list of validation images), \n",
    "4. the number of classes, \n",
    "5. a list of class names.\n",
    "\n",
    "> üìç Important: In this competition, each image can either belong to `opacity` or `none` image-level labels. That's why I have  used the number of classes, `nc` to be 2. YOLOv5 automatically handles the images without any bounding box coordinates. \n",
    "\n",
    "> üìç Note: The `data.yaml` is created in the `yolov5/data` directory as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection\n",
      "{names: [opacity], nc: 1, train: ../covid/images/train, val: ../covid/images/valid}\n"
     ]
    }
   ],
   "source": [
    "# Create .yaml file \n",
    "%cd {HOME}\n",
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = '../covid/images/train',\n",
    "    val = '../covid/images/valid',\n",
    "    nc = 1,\n",
    "    names = ['opacity']\n",
    ")\n",
    "\n",
    "# Note that I am creating the file in the yolov5/data/ directory.\n",
    "with open('tmp/yolov5/data/data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "    \n",
    "%cat tmp/yolov5/data/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçÆ Prepare Bounding Box Coordinated for YOLOv5\n",
    "\n",
    "For every image with **bounding box(es)** a `.txt` file with the same name as the image will be created in the format shown below:\n",
    "\n",
    "* One row per object. <br>\n",
    "* Each row is class `x_center y_center width height format`. <br>\n",
    "* Box coordinates must be in normalized xywh format (from 0 - 1). We can normalize by the boxes in pixels by dividing `x_center` and `width` by image width, and `y_center` and `height` by image height. <br>\n",
    "* Class numbers are zero-indexed (start from 0). <br>\n",
    "\n",
    "> üìç Note: We don't have to remove the images without bounding boxes from the training or validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw bounding box by parsing the row value of the label column.\n",
    "# Ref: https://www.kaggle.com/yujiariyasu/plot-3positive-classes\n",
    "def get_bbox(row):\n",
    "    bboxes = []\n",
    "    bbox = []\n",
    "    for i, l in enumerate(row.label.split(' ')):\n",
    "        if (i % 6 == 0) | (i % 6 == 1):\n",
    "            continue\n",
    "        bbox.append(float(l))\n",
    "        if i % 6 == 5:\n",
    "            bboxes.append(bbox)\n",
    "            bbox = []  \n",
    "            \n",
    "    return bboxes\n",
    "\n",
    "# Scale the bounding boxes according to the size of the resized image. \n",
    "def scale_bbox(row, bboxes):\n",
    "    # Get scaling factor\n",
    "    scale_x = IMG_SIZE/row.dim1\n",
    "    scale_y = IMG_SIZE/row.dim0\n",
    "    \n",
    "    scaled_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x = int(np.round(bbox[0]*scale_x, 4))\n",
    "        y = int(np.round(bbox[1]*scale_y, 4))\n",
    "        x1 = int(np.round(bbox[2]*(scale_x), 4))\n",
    "        y1= int(np.round(bbox[3]*scale_y, 4))\n",
    "\n",
    "        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n",
    "        \n",
    "    return scaled_bboxes\n",
    "\n",
    "# Convert the bounding boxes in YOLO format.\n",
    "def get_yolo_format_bbox(img_w, img_h, bboxes):\n",
    "    yolo_boxes = []\n",
    "    for bbox in bboxes:\n",
    "        w = bbox[2] - bbox[0] # xmax - xmin\n",
    "        h = bbox[3] - bbox[1] # ymax - ymin\n",
    "        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n",
    "        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n",
    "        \n",
    "        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n",
    "    \n",
    "    return yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badf2d31cdbd</td>\n",
       "      <td>[{'x': 484.0363, 'y': 955.76643, 'width': 587....</td>\n",
       "      <td>opacity 1 484.0363 955.76643 1071.75999 1657.7...</td>\n",
       "      <td>c508e7ff4063</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d95766f633e</td>\n",
       "      <td>[{'x': 1821.70335, 'y': 880.30619, 'width': 66...</td>\n",
       "      <td>opacity 1 1821.70335 880.30619 2485.89476 1875...</td>\n",
       "      <td>2c78ef584129</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2400</td>\n",
       "      <td>2880</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951ac929b71</td>\n",
       "      <td>[{'x': 409.13877, 'y': 955.27207, 'width': 115...</td>\n",
       "      <td>opacity 1 409.13877 955.27207 1559.23612 3211....</td>\n",
       "      <td>24cd517d2846</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69522a81a9b6</td>\n",
       "      <td>[{'x': 1654.70833, 'y': 1096.9792, 'width': 78...</td>\n",
       "      <td>opacity 1 1654.70833 1096.9792 2434.94161 1975...</td>\n",
       "      <td>b22e2537daa0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2446</td>\n",
       "      <td>2630</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98e895293a8c</td>\n",
       "      <td>[{'x': 2191.62551, 'y': 1077.50003, 'width': 1...</td>\n",
       "      <td>opacity 1 2191.62551 1077.50003 3729.32302 298...</td>\n",
       "      <td>58072ae8b0f0</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3480</td>\n",
       "      <td>4240</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ceff5e389de0</td>\n",
       "      <td>[{'x': 2140.2, 'y': 1286.25001, 'width': 733.6...</td>\n",
       "      <td>opacity 1 2140.2 1286.25001 2873.89995 2489.75...</td>\n",
       "      <td>6fc05a848fc4</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>4240</td>\n",
       "      <td>3480</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>600343c20434</td>\n",
       "      <td>[{'x': 367.64518, 'y': 1109.91869, 'width': 84...</td>\n",
       "      <td>opacity 1 367.64518 1109.91869 1208.78702 1673...</td>\n",
       "      <td>f6ea0674baa8</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2991</td>\n",
       "      <td>2992</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>d6a56e79a52d</td>\n",
       "      <td>[{'x': 509.73116, 'y': 595.55194, 'width': 440...</td>\n",
       "      <td>opacity 1 509.73116 595.55194 950.34624 1537.2...</td>\n",
       "      <td>816ff8fa8f42</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2320</td>\n",
       "      <td>2828</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>222f258d61f7</td>\n",
       "      <td>[{'x': 1701.8041, 'y': 1190.48126, 'width': 72...</td>\n",
       "      <td>opacity 1 1701.8041 1190.48126 2430.85867 1990...</td>\n",
       "      <td>8a0139211dd5</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>d7a2083fec46</td>\n",
       "      <td>[{'x': 1024.23625, 'y': 1550.79428, 'width': 8...</td>\n",
       "      <td>opacity 1 1024.23625 1550.79428 1865.41752 228...</td>\n",
       "      <td>ab2560a15171</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              boxes  \\\n",
       "0     badf2d31cdbd  [{'x': 484.0363, 'y': 955.76643, 'width': 587....   \n",
       "1     8d95766f633e  [{'x': 1821.70335, 'y': 880.30619, 'width': 66...   \n",
       "2     1951ac929b71  [{'x': 409.13877, 'y': 955.27207, 'width': 115...   \n",
       "3     69522a81a9b6  [{'x': 1654.70833, 'y': 1096.9792, 'width': 78...   \n",
       "4     98e895293a8c  [{'x': 2191.62551, 'y': 1077.50003, 'width': 1...   \n",
       "...            ...                                                ...   \n",
       "6329  ceff5e389de0  [{'x': 2140.2, 'y': 1286.25001, 'width': 733.6...   \n",
       "6330  600343c20434  [{'x': 367.64518, 'y': 1109.91869, 'width': 84...   \n",
       "6331  d6a56e79a52d  [{'x': 509.73116, 'y': 595.55194, 'width': 440...   \n",
       "6332  222f258d61f7  [{'x': 1701.8041, 'y': 1190.48126, 'width': 72...   \n",
       "6333  d7a2083fec46  [{'x': 1024.23625, 'y': 1550.79428, 'width': 8...   \n",
       "\n",
       "                                                  label StudyInstanceUID  \\\n",
       "0     opacity 1 484.0363 955.76643 1071.75999 1657.7...     c508e7ff4063   \n",
       "1     opacity 1 1821.70335 880.30619 2485.89476 1875...     2c78ef584129   \n",
       "2     opacity 1 409.13877 955.27207 1559.23612 3211....     24cd517d2846   \n",
       "3     opacity 1 1654.70833 1096.9792 2434.94161 1975...     b22e2537daa0   \n",
       "4     opacity 1 2191.62551 1077.50003 3729.32302 298...     58072ae8b0f0   \n",
       "...                                                 ...              ...   \n",
       "6329  opacity 1 2140.2 1286.25001 2873.89995 2489.75...     6fc05a848fc4   \n",
       "6330  opacity 1 367.64518 1109.91869 1208.78702 1673...     f6ea0674baa8   \n",
       "6331  opacity 1 509.73116 595.55194 950.34624 1537.2...     816ff8fa8f42   \n",
       "6332  opacity 1 1701.8041 1190.48126 2430.85867 1990...     8a0139211dd5   \n",
       "6333  opacity 1 1024.23625 1550.79428 1865.41752 228...     ab2560a15171   \n",
       "\n",
       "                                                   path image_level  dim0  \\\n",
       "0     input/siim-covid19-resized-to-512px-png/train/...     opacity  2336   \n",
       "1     input/siim-covid19-resized-to-512px-png/train/...     opacity  2400   \n",
       "2     input/siim-covid19-resized-to-512px-png/train/...     opacity  3488   \n",
       "3     input/siim-covid19-resized-to-512px-png/train/...     opacity  2446   \n",
       "4     input/siim-covid19-resized-to-512px-png/train/...     opacity  3480   \n",
       "...                                                 ...         ...   ...   \n",
       "6329  input/siim-covid19-resized-to-512px-png/train/...     opacity  4240   \n",
       "6330  input/siim-covid19-resized-to-512px-png/train/...     opacity  2991   \n",
       "6331  input/siim-covid19-resized-to-512px-png/train/...     opacity  2320   \n",
       "6332  input/siim-covid19-resized-to-512px-png/train/...     opacity  2544   \n",
       "6333  input/siim-covid19-resized-to-512px-png/train/...     opacity  3520   \n",
       "\n",
       "      dim1  split  \n",
       "0     2836  train  \n",
       "1     2880  train  \n",
       "2     4256  train  \n",
       "3     2630  train  \n",
       "4     4240  train  \n",
       "...    ...    ...  \n",
       "6329  3480  valid  \n",
       "6330  2992  valid  \n",
       "6331  2828  valid  \n",
       "6332  3056  valid  \n",
       "6333  4280  valid  \n",
       "\n",
       "[6334 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6334/6334 [00:01<00:00, 4659.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the txt files for bounding box\n",
    "# for i in tqdm(range(10)):\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    # Get image id\n",
    "    img_id = row.id\n",
    "    # Get split\n",
    "    split = row.split\n",
    "    # Get image-level label\n",
    "    label = row.image_level\n",
    "    \n",
    "    if row.split=='train':\n",
    "        file_name = f'tmp/covid/labels/train/{row.id}.txt'\n",
    "    else:\n",
    "        file_name = f'tmp/covid/labels/valid/{row.id}.txt'\n",
    "        \n",
    "    \n",
    "    if label=='opacity':\n",
    "        # Get bboxes\n",
    "        bboxes = get_bbox(row)\n",
    "        # Scale bounding boxes\n",
    "        scale_bboxes = scale_bbox(row, bboxes)\n",
    "        # Format for YOLOv5\n",
    "        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n",
    "        \n",
    "        with open(file_name, 'w') as f:\n",
    "            for bbox in yolo_bboxes:\n",
    "                bbox = [CLASS_NUMBER]+bbox\n",
    "                bbox = [str(i) for i in bbox]\n",
    "                bbox = ' '.join(bbox)\n",
    "#                 print(bbox)\n",
    "                f.write(bbox)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÖ Train with W&B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd tmp/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--img {IMG_SIZE} \\ # Input image size.\n",
    "--batch {BATCH_SIZE} \\ # Batch size\n",
    "--epochs {EPOCHS} \\ # Number of epochs\n",
    "--data data.yaml \\ # Configuration file\n",
    "--weights yolov5l.pt \\ # Model name\n",
    "--save_period 1\\ # Save model after interval\n",
    "--project kaggle-siim-covid # W&B project name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=200, batch_size=16, img_size=[512], rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache_images=False, image_weights=False, device=, multi_scale=False, single_cls=True, adam=False, sync_bn=False, workers=8, project=kaggle-siim-covid, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=1, artifact_alias=latest, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds, for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ v5.0-294-gdd62e2d torch 1.9.0+cu102 CUDA:0 (TITAN Xp, 12194.0625MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir kaggle-siim-covid', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 5 (delta 1), reused 1 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (5/5), done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   3fef117..5d66e48  master     -> origin/master\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/kperkins411/kaggle-siim-covid\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/kperkins411/kaggle-siim-covid/runs/3g2i6pk4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/wandb/run-20210728_011408-3g2i6pk4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
      "  9                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 499 layers, 46631350 parameters, 46631350 gradients, 114.2 GFLOPs\n",
      "\n",
      "Transferred 644/650 items from yolov5l.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 110 .bias, 110 conv.weight, 107 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../covid/labels/train.cache' images and labels... 3435 found, 1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../covid/labels/valid.cache' images and labels... 859 found, 408 \u001b[0m\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.77, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to kaggle-siim-covid/exp11\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     0/199     6.21G   0.07312   0.02552         0   0.09864        17       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.364       0.33      0.249     0.0635\n",
      "Saving model artifact on epoch  1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     1/199     6.82G   0.05761   0.02173         0   0.07934        35       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.449      0.439      0.359     0.0936\n",
      "Saving model artifact on epoch  2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     2/199     6.82G   0.05529   0.02082         0   0.07611        28       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.466      0.402      0.378      0.098\n",
      "Saving model artifact on epoch  3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     3/199     6.82G    0.0548   0.02089         0   0.07569        23       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.262      0.341      0.171     0.0457\n",
      "Saving model artifact on epoch  4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     4/199     6.82G    0.0533   0.02031         0    0.0736        32       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.454      0.412      0.371       0.11\n",
      "Saving model artifact on epoch  5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     5/199     6.82G   0.05237   0.02039         0   0.07276        18       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582       0.43       0.42      0.342      0.101\n",
      "Saving model artifact on epoch  6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     6/199     6.82G    0.0521   0.02027         0   0.07238        26       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.521      0.458       0.44      0.132\n",
      "Saving model artifact on epoch  7\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     7/199     6.82G   0.05119   0.02015         0   0.07134        25       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582       0.51      0.452      0.408      0.116\n",
      "Saving model artifact on epoch  8\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     8/199     6.82G   0.05098   0.01999         0   0.07097        23       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    52/199     6.82G   0.04303   0.01853         0   0.06156        25       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.496       0.45      0.416      0.126\n",
      "Saving model artifact on epoch  53\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    53/199     6.82G   0.04291   0.01841         0   0.06133        36       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.514      0.481       0.43      0.125\n",
      "Saving model artifact on epoch  54\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    54/199     6.82G   0.04266    0.0184         0   0.06106        36       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.524      0.453      0.394      0.119\n",
      "Saving model artifact on epoch  55\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    55/199     6.82G   0.04225   0.01821         0   0.06046        29       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.536      0.462      0.437      0.133\n",
      "Saving model artifact on epoch  56\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    56/199     6.82G   0.04184   0.01836         0    0.0602        22       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.487      0.452      0.395       0.12\n",
      "Saving model artifact on epoch  57\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    57/199     6.82G   0.04158   0.01848         0   0.06007        23       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.524      0.454      0.421      0.125\n",
      "Saving model artifact on epoch  58\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    58/199     6.82G   0.04161   0.01813         0   0.05974        23       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.483       0.47      0.403      0.122\n",
      "Saving model artifact on epoch  59\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    59/199     6.82G   0.04129   0.01819         0   0.05947        22       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.473      0.489      0.417      0.125\n",
      "Saving model artifact on epoch  60\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "    60/199     6.82G   0.04126   0.01825         0   0.05952        39       512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   102/199     6.82G   0.03195   0.01488         0   0.04683        28       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.484      0.455      0.354     0.0999\n",
      "Saving model artifact on epoch  103\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   103/199     6.82G   0.03152   0.01477         0   0.04629        21       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.459      0.447       0.35      0.103\n",
      "Saving model artifact on epoch  104\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   104/199     6.82G   0.03153   0.01464         0   0.04618        28       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.514      0.416      0.363      0.104\n",
      "Saving model artifact on epoch  105\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   105/199     6.82G    0.0311   0.01466         0   0.04576        23       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.507      0.434      0.357      0.102\n",
      "Saving model artifact on epoch  106\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   106/199     6.82G   0.03101    0.0146         0   0.04561        19       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.462      0.459      0.359      0.101\n",
      "Saving model artifact on epoch  107\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   107/199     6.82G   0.03036    0.0142         0   0.04457        33       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582       0.48      0.436      0.344     0.0988\n",
      "Saving model artifact on epoch  108\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   108/199     6.82G   0.03056   0.01402         0   0.04457        14       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.483      0.444      0.349      0.102\n",
      "Saving model artifact on epoch  109\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   109/199     6.82G   0.03022   0.01413         0   0.04435        33       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.484      0.454      0.362      0.106\n",
      "Saving model artifact on epoch  110\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   110/199     6.82G   0.03034   0.01409         0   0.04443        26       512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   152/199     6.82G   0.02238    0.0107         0   0.03308        25       512\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1267       1582      0.493      0.418      0.332      0.095\n",
      "Saving model artifact on epoch  153\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "   153/199     6.82G   0.02251   0.01089         0    0.0334        24       512^C\n",
      "   153/199     6.82G   0.02251   0.01089         0    0.0334        24       512\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/train.py\", line 661, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/train.py\", line 559, in main\n",
      "    train(opt.hyp, opt, device)\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/train.py\", line 339, in train\n",
      "    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img {IMG_SIZE} \\\n",
    "                 --batch {BATCH_SIZE} \\\n",
    "                 --epochs {EPOCHS} \\\n",
    "                 --data data.yaml \\\n",
    "                 --weights yolov5l.pt \\\n",
    "                 --save_period 1\\\n",
    "                 --project kaggle-siim-covid\\\n",
    "                 --single-cls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saved Automatically as Artifact\n",
    "\n",
    "Since it's a kernel based competition, you can easily download the best model from the W&B Artifacts UI and upload as a Kaggle dataset that you can load in your inference kernel (internel disabled).\n",
    "\n",
    "### [Path to saved model $\\rightarrow$](https://wandb.ai/ayush-thakur/kaggle-siim-covid/artifacts/model/run_jbt74n7q_model/4c3ca5752dba99bd227e)\n",
    "\n",
    "![img](https://i.imgur.com/KhRLQvR.png)\n",
    "\n",
    "> üìç Download the model with the `best` alias tagged to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "You will probably use a `Submission.ipynb` kernel to run all the predictions. After training a YOLOv5 based object detector -> head to the artifacts page and download the best model -> upload the model as a Kaggle dataset -> Use it with the submission folder. \n",
    "\n",
    "> üìç Note that you might have to clone the YOLOv5 repository in a Kaggle dataset as well. \n",
    "\n",
    "In this section, I will show you how you can do the inference and modify the predicted bounding box coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '/kaggle/input/siim-covid19-resized-to-512px-jpg/test/' # absolute path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am training the model in this kernel itself, I will not be using the method that I have described above. The best model is saved in the directory `project_name/exp*/weights/best.pt`. In `exp*`, * can be 1, 2, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'kaggle-siim-covid/exp/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--weights {MODEL_PATH} \\ # path to the best model.\n",
    "--source {TEST_PATH} \\ # absolute path to the test images.\n",
    "--img {IMG_SIZE} \\ # Size of image\n",
    "--conf 0.281 \\ # Confidence threshold (default is 0.25)\n",
    "--iou-thres 0.5 \\ # IOU threshold (default is 0.45)\n",
    "--max-det 3 \\ # Number of detections per image (default is 1000) \n",
    "--save-txt \\ # Save predicted bounding box coordinates as txt files\n",
    "--save-conf # Save the confidence of prediction for each bounding box\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['kaggle-siim-covid/exp/weights/best.pt'], source=/kaggle/input/siim-covid19-resized-to-512px-jpg/test/, imgsz=512, conf_thres=0.281, iou_thres=0.5, max_det=3, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
      "YOLOv5 üöÄ v5.0-294-gdd62e2d torch 1.9.0+cu102 CUDA:0 (TITAN Xp, 12194.0625MB)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/detect.py\", line 228, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/detect.py\", line 223, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/detect.py\", line 67, in run\n",
      "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
      "  File \"/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/models/experimental.py\", line 119, in attempt_load\n",
      "    ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\n",
      "  File \"/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'kaggle-siim-covid/exp/weights/best.pt'\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights {MODEL_PATH} \\\n",
    "                  --source {TEST_PATH} \\\n",
    "                  --img {IMG_SIZE} \\\n",
    "                  --conf 0.281 \\\n",
    "                  --iou-thres 0.5 \\\n",
    "                  --max-det 3 \\\n",
    "                  --save-txt \\\n",
    "                  --save-conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the confidence score?\n",
    "\n",
    "1. First first the [W&B run page](https://wandb.ai/ayush-thakur/kaggle-siim-covid/runs/jbt74n7q) generated by training the YOLOv5 model. \n",
    "\n",
    "2. Go to the media panel -> click on the F1_curve.png file to get a rough estimate of the threshold -> go to the Bounding Box Debugger panel and interactively adjust the confidence threshold. \n",
    "\n",
    "![img](https://i.imgur.com/cCUnTBw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìç The bounding box coordinates are saved as text file per image name. It is saved in this directory `runs/detect/exp3/labels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'runs/detect/exp3/labels': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "PRED_PATH = 'runs/detect/exp3/labels'\n",
    "!ls {PRED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: runs/detect/exp3/labels/ba91d37ee459.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Visualize predicted coordinates.\n",
    "%cat runs/detect/exp3/labels/ba91d37ee459.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìç Note: 1 is class id (opacity), the first four float numbers are `x_center`, `y_center`, `width` and `height`. The final float value is `confidence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/exp3/labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-df969faf8c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRED_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of test images predicted as opaque: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/exp3/labels'"
     ]
    }
   ],
   "source": [
    "prediction_files = os.listdir(PRED_PATH)\n",
    "print('Number of test images predicted as opaque: ', len(prediction_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìç Out of 1263 test images, 583 were predicted with `opacity` label and thus we have that many prediction txt files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "In this section, I will show how you can use YOLOv5 as object detector and prepare `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# The submisison requires xmin, ymin, xmax, ymax format. \n",
    "# YOLOv5 returns x_center, y_center, width, height\n",
    "def correct_bbox_format(bboxes):\n",
    "    correct_bboxes = []\n",
    "    for b in bboxes:\n",
    "        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n",
    "        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n",
    "\n",
    "        xmin = xc - int(np.round(w/2))\n",
    "        xmax = xc + int(np.round(w/2))\n",
    "        ymin = yc - int(np.round(h/2))\n",
    "        ymax = yc + int(np.round(h/2))\n",
    "        \n",
    "        correct_bboxes.append([xmin, xmax, ymin, ymax])\n",
    "        \n",
    "    return correct_bboxes\n",
    "\n",
    "# Read the txt file generated by YOLOv5 during inference and extract \n",
    "# confidence and bounding box coordinates.\n",
    "def get_conf_bboxes(file_path):\n",
    "    confidence = []\n",
    "    bboxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            preds = line.strip('\\n').split(' ')\n",
    "            preds = list(map(float, preds))\n",
    "            confidence.append(preds[-1])\n",
    "            bboxes.append(preds[1:-1])\n",
    "    return confidence, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the submisison file\n",
    "sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n",
    "sub_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction loop for submission\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(len(sub_df))):\n",
    "    row = sub_df.loc[i]\n",
    "    id_name = row.id.split('_')[0]\n",
    "    id_level = row.id.split('_')[-1]\n",
    "    \n",
    "    if id_level == 'study':\n",
    "        # do study-level classification\n",
    "        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n",
    "        \n",
    "    elif id_level == 'image':\n",
    "        # we can do image-level classification here.\n",
    "        # also we can rely on the object detector's classification head.\n",
    "        # for this example submisison we will use YOLO's classification head. \n",
    "        # since we already ran the inference we know which test images belong to opacity.\n",
    "        if f'{id_name}.txt' in prediction_files:\n",
    "            # opacity label\n",
    "            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n",
    "            bboxes = correct_bbox_format(bboxes)\n",
    "            pred_string = ''\n",
    "            for j, conf in enumerate(confidence):\n",
    "                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n",
    "            predictions.append(pred_string[:-1]) \n",
    "        else:\n",
    "            predictions.append(\"None 1 0 0 1 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['PredictionString'] = predictions\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best Weights from YOLOv5 (see wandb artifacts best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('kperkins411/kaggle-siim-covid/run_3bh5hck7_model:v199', type='model')\n",
    "artifact_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
