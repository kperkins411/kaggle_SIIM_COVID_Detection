{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0+cu102 (TITAN Xp)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))\n",
    "import torch\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'input/siim-covid19-resized-to-512px-png/train/'\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 48\n",
    "EPOCHS = 35\n",
    "VAL_SPLIT=.15\n",
    "HOME= '~/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection'\n",
    "CLASS_NUMBER=1\n",
    "RANDOM_SEED=42\n",
    "\n",
    "IMAGES_TRAIN_DIR='tmp/covid/images/train'\n",
    "IMAGES_VAL_DIR='tmp/covid/images/valid'\n",
    "LABELS_TRAIN_DIR='tmp/covid/labels/train'\n",
    "LABELS_VAL_DIR='tmp/covid/labels/valid'\n",
    "\n",
    "models={\"yolov5s.pt\":{\"BS\":48,\"EPOCHS\":EPOCHS}, \n",
    "        \"yolov5m.pt\":{\"BS\":32,\"EPOCHS\":EPOCHS}, \n",
    "        \"yolov5l.pt\":{\"BS\":16,\"EPOCHS\":EPOCHS}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚òÄÔ∏è Setup Yolov5 and wandb\n",
    "\n",
    "According to the official [Train Custom Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data) guide, YOLOv5 requires a certain directory structure. \n",
    "\n",
    "```\n",
    "/parent_folder\n",
    "    /dataset\n",
    "         /images\n",
    "         /labels\n",
    "    /yolov5\n",
    "```\n",
    "\n",
    "* Create a `/tmp` directory. <br>\n",
    "* Download YOLOv5 repository and pip install the required dependencies. <br>\n",
    "* Install the latest version of W&B and login with your wandb account. You can create your free W&B account [here](https://wandb.ai/site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚Äòtmp‚Äô: File exists\n",
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp\n",
      "Yolo probably installed already\n",
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection\n"
     ]
    }
   ],
   "source": [
    "#make a directory for yolov5\n",
    "!mkdir tmp\n",
    "%cd tmp\n",
    "\n",
    "# Download YOLOv5 if not already there\n",
    "if os.path.isdir('yolov5'):\n",
    "    print(\"Yolo probably installed already\")\n",
    "else:\n",
    "    !git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "    %cd yolov5\n",
    "\n",
    "    # Install dependenciesimages\n",
    "    %pip install -qr requirements.txt  # install dependencies\n",
    "    %cd ..\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install W&B \n",
    "!pip install -q --upgrade wandb\n",
    "\n",
    "# Login \n",
    "key = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "# print(key)\n",
    "import wandb\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî® Prepare Dataset\n",
    "\n",
    "This is the most important section when it comes to training an object detector with YOLOv5. The directory structure, bounding box format, etc must be in the correct order. This section builds every piece needed to train a YOLOv5 model.\n",
    "\n",
    "I am using [xhlulu's](https://www.kaggle.com/xhlulu) resized dataset. The uploaded 256x256 Kaggle dataset is [here](https://www.kaggle.com/xhlulu/siim-covid19-resized-to-256px-jpg). Find other image resolutions [here](https://www.kaggle.com/c/siim-covid19-detection/discussion/239918).\n",
    "\n",
    "* Create train-validation split. <br>\n",
    "* Create required `/dataset` folder structure and more the images to that folder. <br>\n",
    "* Create `data.yaml` file needed to train the model. <br>\n",
    "* Create bounding box coordinates in the required YOLO format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "                                                path image_level  \n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...        none  \n",
       "2  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "3  input/siim-covid19-resized-to-512px-png/train/...     opacity  \n",
       "4  input/siim-covid19-resized-to-512px-png/train/...     opacity  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image level csv file\n",
    "df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')\n",
    "\n",
    "# Modify values in the id column\n",
    "df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)\n",
    "# Add absolute path\n",
    "df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\n",
    "# Get image level labels\n",
    "df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opacity    4294\n",
       "none       2040\n",
       "Name: image_level, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d8ba599611e5</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29b23a11d1e4</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  dim0  dim1\n",
       "0  d8ba599611e5  2336  2836\n",
       "1  29b23a11d1e4  3488  4256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load meta.csv file\n",
    "# Original dimensions are required to scale the bounding box coordinates appropriately.\n",
    "meta_df = pd.read_csv('input/siim-covid19-resized-to-512px-png/meta.csv')\n",
    "train_meta_df = meta_df.loc[meta_df.split == 'train']\n",
    "train_meta_df = train_meta_df.drop('split', axis=1)\n",
    "train_meta_df.columns = ['id', 'dim0', 'dim1']\n",
    "\n",
    "train_meta_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "\n",
       "                                                path image_level  dim0  dim1  \n",
       "0  input/siim-covid19-resized-to-512px-png/train/...     opacity  3488  4256  \n",
       "1  input/siim-covid19-resized-to-512px-png/train/...        none  2320  2832  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge both the dataframes\n",
    "df = df.merge(train_meta_df, on='id',how=\"left\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçò Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 6334, training images: 5383. validation images: 951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Create train and validation split.\n",
    "train_df, valid_df = train_test_split(df, test_size=VAL_SPLIT, random_state=RANDOM_SEED, stratify=df.image_level.values)\n",
    "\n",
    "train_df.loc[:, 'split'] = 'train'\n",
    "valid_df.loc[:, 'split'] = 'valid'\n",
    "\n",
    "df = pd.concat([train_df, valid_df]).reset_index(drop=True)\n",
    "print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçö Prepare Required Folder Structure\n",
    "\n",
    "The required folder structure for the dataset directory is: \n",
    "\n",
    "```\n",
    "/parent_folder\n",
    "    /dataset\n",
    "         /images\n",
    "             /train\n",
    "             /val\n",
    "         /labels\n",
    "             /train\n",
    "             /val\n",
    "    /yolov5\n",
    "```\n",
    "\n",
    "Note that I have named the directory `covid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6334/6334 [00:01<00:00, 5652.16it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(LABELS_VAL_DIR, exist_ok=True)\n",
    "\n",
    "# Move the images to relevant split folder.\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    if row.split == 'train':\n",
    "        copyfile(row.path, f'{IMAGES_TRAIN_DIR}/{row.id}.png')\n",
    "    else:\n",
    "        copyfile(row.path, f'{IMAGES_VAL_DIR}/{row.id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçú Create `.YAML` file\n",
    "\n",
    "The `data.yaml`, is the dataset configuration file that defines \n",
    "\n",
    "1. an \"optional\" download command/URL for auto-downloading, \n",
    "2. a path to a directory of training images (or path to a *.txt file with a list of training images), \n",
    "3. a path to a directory of validation images (or path to a *.txt file with a list of validation images), \n",
    "4. the number of classes, \n",
    "5. a list of class names.\n",
    "\n",
    "> üìç Important: In this competition, each image can either belong to `opacity` or `none` image-level labels. That's why I have  used the number of classes, `nc` to be 2. YOLOv5 automatically handles the images without any bounding box coordinates. \n",
    "\n",
    "> üìç Note: The `data.yaml` is created in the `yolov5/data` directory as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection\n",
      "{names: [opacity], nc: 1, train: ../covid/images/train, val: ../covid/images/valid}\n"
     ]
    }
   ],
   "source": [
    "# Create .yaml file \n",
    "%cd {HOME}\n",
    "import yaml\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = '../covid/images/train',\n",
    "    val = '../covid/images/valid',\n",
    "    nc = 1,\n",
    "    names = ['opacity']\n",
    ")\n",
    "\n",
    "# Note that I am creating the file in the yolov5/data/ directory.\n",
    "with open('tmp/yolov5/data/data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "    \n",
    "%cat tmp/yolov5/data/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçÆ Prepare Bounding Box Coordinated for YOLOv5\n",
    "\n",
    "For every image with **bounding box(es)** a `.txt` file with the same name as the image will be created in the format shown below:\n",
    "\n",
    "* One row per object. <br>\n",
    "* Each row is class `x_center y_center width height format`. <br>\n",
    "* Box coordinates must be in normalized xywh format (from 0 - 1). We can normalize by the boxes in pixels by dividing `x_center` and `width` by image width, and `y_center` and `height` by image height. <br>\n",
    "* Class numbers are zero-indexed (start from 0). <br>\n",
    "\n",
    "> üìç Note: We don't have to remove the images without bounding boxes from the training or validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw bounding box by parsing the row value of the label column.\n",
    "# Ref: https://www.kaggle.com/yujiariyasu/plot-3positive-classes\n",
    "def get_bbox(row):\n",
    "    bboxes = []\n",
    "    bbox = []\n",
    "    for i, l in enumerate(row.label.split(' ')):\n",
    "        if (i % 6 == 0) | (i % 6 == 1):\n",
    "            continue\n",
    "        bbox.append(float(l))\n",
    "        if i % 6 == 5:\n",
    "            bboxes.append(bbox)\n",
    "            bbox = []  \n",
    "            \n",
    "    return bboxes\n",
    "\n",
    "# Scale the bounding boxes according to the size of the resized image. \n",
    "def scale_bbox(row, bboxes):\n",
    "    # Get scaling factor\n",
    "    scale_x = IMG_SIZE/row.dim1\n",
    "    scale_y = IMG_SIZE/row.dim0\n",
    "    \n",
    "    scaled_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x = int(np.round(bbox[0]*scale_x, 4))\n",
    "        y = int(np.round(bbox[1]*scale_y, 4))\n",
    "        x1 = int(np.round(bbox[2]*(scale_x), 4))\n",
    "        y1= int(np.round(bbox[3]*scale_y, 4))\n",
    "\n",
    "        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n",
    "        \n",
    "    return scaled_bboxes\n",
    "\n",
    "# Convert the bounding boxes in YOLO format.\n",
    "def get_yolo_format_bbox(img_w, img_h, bboxes):\n",
    "    yolo_boxes = []\n",
    "    for bbox in bboxes:\n",
    "        w = bbox[2] - bbox[0] # xmax - xmin\n",
    "        h = bbox[3] - bbox[1] # ymax - ymin\n",
    "        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n",
    "        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n",
    "        \n",
    "        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n",
    "    \n",
    "    return yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>path</th>\n",
       "      <th>image_level</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc54237ef4db</td>\n",
       "      <td>[{'x': 1657.98161, 'y': 616.51372, 'width': 65...</td>\n",
       "      <td>opacity 1 1657.98161 616.51372 2309.72477 995....</td>\n",
       "      <td>047b450939fd</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2400</td>\n",
       "      <td>2880</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c957ee30525d</td>\n",
       "      <td>[{'x': 670.92926, 'y': 1034.5932, 'width': 679...</td>\n",
       "      <td>opacity 1 670.92926 1034.5932 1350.47753999999...</td>\n",
       "      <td>b94e0c41bcee</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2806</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5df652c28a0a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>1e88ad314aa9</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8fa2ed829e2b</td>\n",
       "      <td>[{'x': 1711.57423, 'y': 852.64, 'width': 778.6...</td>\n",
       "      <td>opacity 1 1711.57423 852.64 2490.2409 1748.106...</td>\n",
       "      <td>671caa8e6113</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2336</td>\n",
       "      <td>2836</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0159b677bda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>366fc85a2ac8</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>d8ef6a6d4981</td>\n",
       "      <td>[{'x': 2592.0002, 'y': 569.60007, 'width': 154...</td>\n",
       "      <td>opacity 1 2592.0002 569.60007 4140.8 2310.3999...</td>\n",
       "      <td>f40f145b6d3a</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>8fa48096e899</td>\n",
       "      <td>[{'x': 490.0611, 'y': 1009.83553, 'width': 321...</td>\n",
       "      <td>opacity 1 490.0611 1009.83553 811.71244 2179.2...</td>\n",
       "      <td>03461d2a218f</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3032</td>\n",
       "      <td>3032</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>c5989c8376dd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>d53147ecb090</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>none</td>\n",
       "      <td>3032</td>\n",
       "      <td>3032</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>c77674444141</td>\n",
       "      <td>[{'x': 1039.43829, 'y': 936.51318, 'width': 89...</td>\n",
       "      <td>opacity 1 1039.43829 936.51318 1930.26068 2438...</td>\n",
       "      <td>3fd1aead516b</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3480</td>\n",
       "      <td>4248</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>a0eab82cc525</td>\n",
       "      <td>[{'x': 1788.66749, 'y': 815.12422, 'width': 66...</td>\n",
       "      <td>opacity 1 1788.66749 815.12422 2453.62461 1387...</td>\n",
       "      <td>f5bc6b85d2b1</td>\n",
       "      <td>input/siim-covid19-resized-to-512px-png/train/...</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              boxes  \\\n",
       "0     cc54237ef4db  [{'x': 1657.98161, 'y': 616.51372, 'width': 65...   \n",
       "1     c957ee30525d  [{'x': 670.92926, 'y': 1034.5932, 'width': 679...   \n",
       "2     5df652c28a0a                                                NaN   \n",
       "3     8fa2ed829e2b  [{'x': 1711.57423, 'y': 852.64, 'width': 778.6...   \n",
       "4     c0159b677bda                                                NaN   \n",
       "...            ...                                                ...   \n",
       "6329  d8ef6a6d4981  [{'x': 2592.0002, 'y': 569.60007, 'width': 154...   \n",
       "6330  8fa48096e899  [{'x': 490.0611, 'y': 1009.83553, 'width': 321...   \n",
       "6331  c5989c8376dd                                                NaN   \n",
       "6332  c77674444141  [{'x': 1039.43829, 'y': 936.51318, 'width': 89...   \n",
       "6333  a0eab82cc525  [{'x': 1788.66749, 'y': 815.12422, 'width': 66...   \n",
       "\n",
       "                                                  label StudyInstanceUID  \\\n",
       "0     opacity 1 1657.98161 616.51372 2309.72477 995....     047b450939fd   \n",
       "1     opacity 1 670.92926 1034.5932 1350.47753999999...     b94e0c41bcee   \n",
       "2                                        none 1 0 0 1 1     1e88ad314aa9   \n",
       "3     opacity 1 1711.57423 852.64 2490.2409 1748.106...     671caa8e6113   \n",
       "4                                        none 1 0 0 1 1     366fc85a2ac8   \n",
       "...                                                 ...              ...   \n",
       "6329  opacity 1 2592.0002 569.60007 4140.8 2310.3999...     f40f145b6d3a   \n",
       "6330  opacity 1 490.0611 1009.83553 811.71244 2179.2...     03461d2a218f   \n",
       "6331                                     none 1 0 0 1 1     d53147ecb090   \n",
       "6332  opacity 1 1039.43829 936.51318 1930.26068 2438...     3fd1aead516b   \n",
       "6333  opacity 1 1788.66749 815.12422 2453.62461 1387...     f5bc6b85d2b1   \n",
       "\n",
       "                                                   path image_level  dim0  \\\n",
       "0     input/siim-covid19-resized-to-512px-png/train/...     opacity  2400   \n",
       "1     input/siim-covid19-resized-to-512px-png/train/...     opacity  2806   \n",
       "2     input/siim-covid19-resized-to-512px-png/train/...        none  3056   \n",
       "3     input/siim-covid19-resized-to-512px-png/train/...     opacity  2336   \n",
       "4     input/siim-covid19-resized-to-512px-png/train/...        none  3488   \n",
       "...                                                 ...         ...   ...   \n",
       "6329  input/siim-covid19-resized-to-512px-png/train/...     opacity  3488   \n",
       "6330  input/siim-covid19-resized-to-512px-png/train/...     opacity  3032   \n",
       "6331  input/siim-covid19-resized-to-512px-png/train/...        none  3032   \n",
       "6332  input/siim-covid19-resized-to-512px-png/train/...     opacity  3480   \n",
       "6333  input/siim-covid19-resized-to-512px-png/train/...     opacity  2544   \n",
       "\n",
       "      dim1  split  \n",
       "0     2880  train  \n",
       "1     3056  train  \n",
       "2     2544  train  \n",
       "3     2836  train  \n",
       "4     4256  train  \n",
       "...    ...    ...  \n",
       "6329  4256  valid  \n",
       "6330  3032  valid  \n",
       "6331  3032  valid  \n",
       "6332  4248  valid  \n",
       "6333  3056  valid  \n",
       "\n",
       "[6334 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6334/6334 [00:01<00:00, 4671.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the txt files for bounding boxs\n",
    "# for i in tqdm(range(10)):\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.loc[i]\n",
    "    # Get image id\n",
    "    img_id = row.id\n",
    "    # Get split\n",
    "    split = row.split\n",
    "    # Get image-level label\n",
    "    label = row.image_level\n",
    "    \n",
    "    if row.split=='train':\n",
    "        file_name = f'tmp/covid/labels/train/{row.id}.txt'\n",
    "    else:\n",
    "        file_name = f'tmp/covid/labels/valid/{row.id}.txt'\n",
    "        \n",
    "    \n",
    "    if label=='opacity':\n",
    "        # Get bboxes\n",
    "        bboxes = get_bbox(row)\n",
    "        # Scale bounding boxes\n",
    "        scale_bboxes = scale_bbox(row, bboxes)\n",
    "        # Format for YOLOv5\n",
    "        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n",
    "        \n",
    "        with open(file_name, 'w') as f:\n",
    "            for bbox in yolo_bboxes:\n",
    "                bbox = [CLASS_NUMBER]+bbox\n",
    "                bbox = [str(i) for i in bbox]\n",
    "                bbox = ' '.join(bbox)\n",
    "#                 print(bbox)\n",
    "                f.write(bbox)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÖ Train with W&B\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--img {IMG_SIZE} \\ # Input image size.\n",
    "--batch {BATCH_SIZE} \\ # Batch size\n",
    "--epochs {EPOCHS} \\ # Number of epochs\n",
    "--data data.yaml \\ # Configuration file\n",
    "--weights yolov5l.pt \\ # Model name\n",
    "--save_period 1\\ # Save model after interval\n",
    "--project kaggle-siim-covid # W&B project name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=35, batch_size=48, img_size=[640], rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache_images=False, image_weights=False, device=, multi_scale=False, single_cls=True, adam=False, sync_bn=False, workers=8, project=kaggle-siim-covid, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=2, artifact_alias=latest, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds, for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ v5.0-294-gdd62e2d torch 1.9.0+cu102 CUDA:0 (TITAN Xp, 12194.0625MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir kaggle-siim-covid', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.11.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/kperkins411/kaggle-siim-covid\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/kperkins411/kaggle-siim-covid/runs/g2d2kw9w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/keith/AA_jupyter_tuts/kaggle_SIIM_COVID_Detection/tmp/yolov5/wandb/run-20210730_213416-g2d2kw9w\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "/home/keith/anaconda3/envs/p39/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 356/362 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.000375\n",
      "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../covid/labels/train' images and labels...3649 found, 1734 mis\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../covid/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../covid/labels/valid' images and labels...645 found, 306 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../covid/labels/valid.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.33, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to kaggle-siim-covid/exp16\n",
      "Starting training for 35 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      0/34     9.36G   0.08172   0.02644         0    0.1082        16       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.106      0.192     0.0567     0.0126\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      1/34     10.7G   0.06003   0.02487         0    0.0849        12       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.212      0.266      0.139     0.0297\n",
      "Saving model artifact on epoch  2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      2/34     10.7G   0.05578   0.02273         0   0.07851        13       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.431      0.357      0.296     0.0797\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      3/34     10.7G   0.05464   0.02203         0   0.07667        19       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.418      0.336      0.291     0.0733\n",
      "Saving model artifact on epoch  4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      4/34     10.7G   0.05307   0.02175         0   0.07482        20       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.447      0.396      0.334     0.0906\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      5/34     10.7G   0.05237   0.02173         0    0.0741        21       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181      0.458       0.32      0.315     0.0887\n",
      "Saving model artifact on epoch  6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      6/34     10.7G   0.05161   0.02122         0   0.07283        20       640\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        951       1181       0.33      0.411      0.248     0.0639\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      7/34     10.7G   0.05145   0.02127         0   0.07273       116       640"
     ]
    }
   ],
   "source": [
    "%cd tmp/yolov5/\n",
    "for key, val in models.items():\n",
    "    !python train.py --img {IMG_SIZE} \\\n",
    "                     --batch {val[\"BS\"]} \\\n",
    "                     --epochs {val[\"EPOCHS\"]} \\\n",
    "                     --data data.yaml \\\n",
    "                     --weights {key} \\\n",
    "                     --save_period 2\\\n",
    "                     --project kaggle-siim-covid\\\n",
    "                     --single-cls\n",
    "%cd tmp/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "In this section, I will show how you can use YOLOv5 as object detector and prepare `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# The submisison requires xmin, ymin, xmax, ymax format. \n",
    "# YOLOv5 returns x_center, y_center, width, height\n",
    "def correct_bbox_format(bboxes):\n",
    "    correct_bboxes = []\n",
    "    for b in bboxes:\n",
    "        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n",
    "        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n",
    "\n",
    "        xmin = xc - int(np.round(w/2))\n",
    "        xmax = xc + int(np.round(w/2))\n",
    "        ymin = yc - int(np.round(h/2))\n",
    "        ymax = yc + int(np.round(h/2))\n",
    "        \n",
    "        correct_bboxes.append([xmin, xmax, ymin, ymax])\n",
    "        \n",
    "    return correct_bboxes\n",
    "\n",
    "# Read the txt file generated by YOLOv5 during inference and extract \n",
    "# confidence and bounding box coordinates.\n",
    "def get_conf_bboxes(file_path):\n",
    "    confidence = []\n",
    "    bboxes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            preds = line.strip('\\n').split(' ')\n",
    "            preds = list(map(float, preds))\n",
    "            confidence.append(preds[-1])\n",
    "            bboxes.append(preds[1:-1])\n",
    "    return confidence, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the submisison file\n",
    "# sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "# sub_df.tail()\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction loop for submission\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(len(sub_df))):\n",
    "    row = sub_df.loc[i]\n",
    "    id_name = row.id.split('_')[0]\n",
    "    id_level = row.id.split('_')[-1]\n",
    "    \n",
    "    if id_level == 'study':\n",
    "        # do study-level classification\n",
    "        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n",
    "        \n",
    "    elif id_level == 'image':\n",
    "        # we can do image-level classification here.\n",
    "        # also we can rely on the object detector's classification head.\n",
    "        # for this example submisison we will use YOLO's classification head. \n",
    "        # since we already ran the inference we know which test images belong to opacity.\n",
    "        if f'{id_name}.txt' in prediction_files:\n",
    "            # opacity label\n",
    "            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')\n",
    "            bboxes = correct_bbox_format(bboxes)\n",
    "            pred_string = ''\n",
    "            for j, conf in enumerate(confidence):\n",
    "                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n",
    "            predictions.append(pred_string[:-1]) \n",
    "        else:\n",
    "            predictions.append(\"None 1 0 0 1 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['PredictionString'] = predictions\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
