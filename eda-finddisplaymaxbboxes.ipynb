{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:01:48.425231Z",
     "start_time": "2021-06-03T00:01:48.414825Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "# setting default template to plotly_white for all visualizations\n",
    "pio.templates.default = \"plotly_white\"\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "import utils_eda as uteda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './input/siim-covid19-detection'\n",
    "submission = pd.read_csv(os.path.join(PATH,'sample_submission.csv'), index_col=None)\n",
    "image_df = pd.read_csv(os.path.join(PATH,'train_image_level.csv'), index_col=None)\n",
    "study_df = pd.read_csv(os.path.join(PATH,'train_study_level.csv'), index_col=None)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"Train image level csv shape : {image_df.shape}\\nTrain study level csv shape : {study_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.head(2)\n",
    "len(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df.head(2)\n",
    "len(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of all the files\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "all_files = []\n",
    "trn_files = uteda.get_files(PATH+'/train')\n",
    "test_files = uteda.get_files(PATH+'/test')\n",
    "\n",
    "print(f'number train dcms={len(trn_files)}, number test dcms from test dir={len(test_files)},\\nsample_submission.csv has {len(submission)} entries, this includes 1263 images + 1214 studies ')\n",
    "all_files = trn_files+test_files\n",
    "# ds=dcmread(all_files[0])\n",
    "# dir(ds)\n",
    "# ds.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getinfo(ds,col='id'):\n",
    "    #lets see if the ds file has only studies\n",
    "    #and what the mix is\n",
    "    #assumme we are looking at id column\n",
    "    out = ds[col].map(lambda x:x.split('_')[1])\n",
    "    print (f'total records={out.shape}')\n",
    "    print(f'unique vals={set(out)}')\n",
    "    for val in (set(out)):\n",
    "        f = lambda x:x==val\n",
    "        tot = sum(map(f,out))\n",
    "        print(f'sum {val} = {tot}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getinfo(image_df)\n",
    "getinfo(study_df)\n",
    "getinfo(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_from_kaggle_sub## Where are submission files? In test dir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of _image and _study\n",
    "image_df['id']=image_df['id'].map(lambda x: x.split('_')[0])\n",
    "study_df['id']=study_df['id'].map(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the bounding box distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find max number bounding boxes in train set bounding boxes\n",
    "f=lambda x:x.count('{') if type(x) is str else 0\n",
    "numb_bboxes_per_row=list(map(f,image_df.boxes))\n",
    "m=max(numb_bboxes_per_row)\n",
    "print(f'Maximum number of bounding boxes={m}\\n')\n",
    "tots=0\n",
    "for i in range(0, m+1):\n",
    "    tot = numb_bboxes_per_row.count(i)\n",
    "    print(f'number images with {i} bounding boxes={tot}')\n",
    "    tots+=tot\n",
    "print(f'\\nTotal images={tots}, total with bounding boxes={tots-numb_bboxes_per_row.count(0)}')\n",
    "# numb_bboxes_per_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df that ONLY contains images that have numb_boxes bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all rows that have this many boxes\n",
    "numb_boxes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_with_numb_boxes(df, numb_boxes):\n",
    "    '''\n",
    "     find dcm files with numb_boxes bounding boxes\n",
    "     works by finding number of dicts by checking for the first { char in the dict\n",
    "     param:  df- loaded from train_image_level.csv (there are some images with no bounding boxes\n",
    "     so the boxes field is blank)\n",
    "             numb_boxes-return df with rows with this many bounding boxes\n",
    "     df \n",
    "     returns: dataframe\n",
    "    '''\n",
    "    f=lambda x:x.count('{') if type(x) is str else 0\n",
    "    numb_bboxes_per_row=list(map(f,df.boxes))\n",
    "    mask= map(lambda x:x==numb_boxes,numb_bboxes_per_row)\n",
    "    return df[list(mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=get_rows_with_numb_boxes(image_df,numb_boxes)\n",
    "# df1=get_rows(image_df,8)#max bounding boxes, just 1 of these\n",
    "print(f'Dataframe contains { len(df1)} rows with {numb_boxes} bounding boxes')\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex start from 0, get rid of old non sequential index \n",
    "df1.reset_index(inplace=True, drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_eda as uteda\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "def copy_dicom_img_to_dir(row, pth_dicom_fles, pth_destdir):\n",
    "    '''\n",
    "    row - pandas series\n",
    "    pth_dicom_fles - 'input/siim-covid19-detection/train/' for ex\n",
    "    pth_destdir - where all images will wind up (like ''./test_tmp/'')\n",
    "    return im.shape(height,width) to be logged\n",
    "    \n",
    "    ex.\n",
    "    # copy imag to test dir\n",
    "    for i in range(MAX_ROWS):\n",
    "         copy_dicom_img_to_dir(df1.loc[i],TRAIN_DIR ,TEST_DIR )\n",
    "    \n",
    "    '''\n",
    "    study=  row.loc['StudyInstanceUID']\n",
    "    dcm_file=row.loc['id']\n",
    "    \n",
    "    #create a path to the study\n",
    "    pth =  pth_dicom_fles + row.loc['StudyInstanceUID']\n",
    "\n",
    "    #get all dicom files from the study\n",
    "    dcms = uteda.get_files(pth) \n",
    "\n",
    "    if (len(dcms)>1):\n",
    "        #find the correct image\n",
    "        dcms=list(filter(lambda x:dcm_file in x, dcms))\n",
    "   \n",
    "    #get the image\n",
    "    img=uteda.dicom2array(dcms[0])\n",
    "    \n",
    "    #save it to path\n",
    "    if not os.path.exists(pth_destdir):\n",
    "        os.mkdir(pth_destdir)\n",
    "\n",
    "    im = Image.fromarray(img)     \n",
    "    im.save(pth_destdir+dcm_file+'.png')\n",
    "    return img.shape\n",
    "\n",
    "def load_img( pth_destdir, imagename):\n",
    "    '''\n",
    "    just loads an image\n",
    "    ex.\n",
    "    nme = df1.loc[0,'id']+'.png'\n",
    "    im= load_img( TEST_DIR, nme)\n",
    "    '''\n",
    "    return Image.open(pth_destdir + imagename)\n",
    "    \n",
    "def get_boxes(row):\n",
    "    '''\n",
    "    Convert the string that contaings bounding boxes \n",
    "    into a list of dicts and return\n",
    "    ex.\n",
    "    # get boxes\n",
    "    all_boxes=[]\n",
    "    for i in range(MAX_ROWS):\n",
    "        all_boxes.append(get_boxes(df1.loc[i]))\n",
    "    '''\n",
    "\n",
    "    if (pd.isnull(row.loc['boxes'])):\n",
    "        return []\n",
    "    \n",
    "    boxes=row.loc['boxes'].replace('\\'','\"')\n",
    "    return json.loads(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine maximum predictions to make from df1 result set\n",
    "## Copy images to test dir and get image bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS=min(20,len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the boxes for the first MAX_ROWS rows of df1 and save the images associated with the dicom files\n",
    "import json\n",
    "TRAIN_DIR='./input/siim-covid19-detection/train/'\n",
    "TEST_DIR='./test_tmp/'\n",
    "\n",
    "# get boxes\n",
    "all_boxes=[]\n",
    "for i in range(MAX_ROWS):\n",
    "    all_boxes.append(get_boxes(df1.loc[i]))\n",
    "\n",
    "# copy imag to test dir\n",
    "for i in range(MAX_ROWS):\n",
    "     copy_dicom_img_to_dir(df1.loc[i],TRAIN_DIR ,TEST_DIR )\n",
    "\n",
    "print(all_boxes)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the image and only ground truth bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nme = df1.loc[0,'id']+'.png'\n",
    "im= load_img( TEST_DIR, nme)\n",
    "im=np.array(im)\n",
    "height,width = im.shape\n",
    "\n",
    "boxes=get_boxes(df1.loc[0])\n",
    "\n",
    "#plot it with the b_boxes\n",
    "uteda.plot_img_with_bboxes(im,nme, boxes, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained yolov5 model and run predictions on files in TEST_DIR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "\n",
    "# MODEL1_PATH_2CLASSES ='/artifacts/run_3bh5hck7_model:v199/best.pt'#use alone\n",
    "MODEL_PATH_1CLASS=cwd +\"/best_exp10_yolov5l_img512_1class.pt\" #can ensemble with below\n",
    "MODEL_PATH_1CLASS_KAGGLE = cwd +'/best_from_kaggle_sub_1class.pt'\n",
    "TEST_DIR=cwd+'/test_tmp/'\n",
    "\n",
    "#used for debugging yolov5/detect.py in seperate pycharm session\n",
    "print(MODEL_PATH_1CLASS)\n",
    "print(MODEL_PATH_1CLASS_KAGGLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models, or ensembles of models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys= name of the predict output dir\n",
    "# vals=model weights we are using per run \n",
    "run_names=['ENSEMBLE','MODEL_PATH_1CLASS','MODEL_PATH_1CLASS_KAGGLE']\n",
    "model_names=[ MODEL_PATH_1CLASS + \" \"+MODEL_PATH_1CLASS_KAGGLE, MODEL_PATH_1CLASS, MODEL_PATH_1CLASS_KAGGLE]\n",
    "model_sel=dict(zip(run_names,model_names))\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "\n",
    "for key, val in model_sel.items():   \n",
    "    %rm -rf ./runs/detect/{key}\n",
    "    params=\"--weights \" + val+\" --source \" + TEST_DIR+ \"  --img 512 --conf 0.281 --iou-thres 0.5 --max-det 8  --save-txt  --save-conf --name \" + key + \" --exist-ok\"\n",
    "\n",
    "    !python detect.py {params}\n",
    "# #get back to correct dir\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels saved to runs/detect/{model_sel key}/labels, 1st is class, last is confidence.  Looks like following\n",
    "1 0.326869 0.343108 0.252468 0.463613 0.402857 <br>\n",
    "1 0.695874 0.373716 0.246474 0.478596 0.450281\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list images we tested on\n",
    "all_files = []\n",
    "for dirname,_,filenames in os.walk(TEST_DIR):\n",
    "    for filename in filenames:\n",
    "        all_files.append(os.path.join(dirname, filename))\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an image, the ground truth bounding boxes, and 1 or more predicted bounding boxes and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://www.kaggle.com/embed/rajsengo/beginner-eda-siim-covid-19-detection?cellId=14&cellIds=13&kernelSessionId=64636915\" height=\"300\" style=\"margin: 0 auto; width: 100%; max-width: 950px;\" frameborder=\"0\" scrolling=\"auto\" title=\"[Beginner EDA] SIIM COVID-19 Detection\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR='./yolov5/runs/detect/'\n",
    "\n",
    "# The submisison requires xmin, ymin, xmax, ymax format. \n",
    "# YOLOv5 returns x_center, y_center, width, height\n",
    "def correct_bbox_format(bboxes, orig_width, orig_height):\n",
    "    correct_bboxes = []\n",
    "    for b in bboxes:\n",
    "        xc, yc = int(np.round(b[1]*orig_width)), int(np.round(b[2]*orig_height))\n",
    "        w, h = int(np.round(b[3]*orig_width)), int(np.round(b[4]*orig_height))\n",
    "\n",
    "        xmin= xc - int(np.round(w/2))\n",
    "        ymin= yc - int(np.round(h/2))\n",
    "        xmax= xc + int(np.round(w/2))\n",
    "        ymax= yc + int(np.round(h/2))\n",
    "        conf= b[5]\n",
    "        \n",
    "        correct_bboxes.append([xmin, ymin, xmax, ymax, conf])\n",
    "        \n",
    "    return correct_bboxes\n",
    "\n",
    "def get_pred_bboxes(img_name, run_names, run_dir,orig_width=None, orig_height=None):\n",
    "    '''\n",
    "    img_name name + suffix\n",
    "    get all the bounding boxes for img that are stored in multiple run directories\n",
    "    '''\n",
    "    if(orig_width is None or orig_height is None):\n",
    "        im= load_img( TEST_DIR, img_name)\n",
    "        im=np.array(im)\n",
    "        orig_height,orig_width = im.shape\n",
    "    \n",
    "    results=[]\n",
    "    for dir in run_names:\n",
    "        #convert bounding boxes into lists of floats\n",
    "        pred_boxes_and_confidence=[]\n",
    "        \n",
    "        #file to open\n",
    "        fle = OUT_DIR+dir+ '/labels/' + img_name.split('.')[0] +'.txt'\n",
    "        if not os.path.isfile(fle):\n",
    "            print(f'Missing label file for image {img_name} for run {dir}' )\n",
    "            results.append([])\n",
    "            continue\n",
    "            \n",
    "        with open(fle) as f:\n",
    "            lines=f.readlines()\n",
    "            for lne in lines:\n",
    "                lne=lne.replace('\\n','')\n",
    "                lne=\"[\" +lne.replace(' ',',') +\"]\"\n",
    "                lne=json.loads(lne)               \n",
    "                pred_boxes_and_confidence.append(lne)\n",
    "        pred_boxes = correct_bbox_format(pred_boxes_and_confidence,orig_width,orig_height)\n",
    "        \n",
    "        #convert to a dict\n",
    "        keys=[\"x1\",\"y1\",\"x2\",\"y2\",\"conf\"]\n",
    "        for i,b in enumerate(pred_boxes):\n",
    "            pred_boxes[i]=dict(zip(keys,b))\n",
    "        results.append(pred_boxes)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tying it together, show images, ground truth and all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(df,max_rows, test_dir,out_dir, run_names, show_image):\n",
    "    for i in range(max_rows):\n",
    "        row=df.loc[i]\n",
    "\n",
    "        img_name = row.loc['id']+'.png'\n",
    "\n",
    "        img= load_img( test_dir, img_name)\n",
    "        img=np.array(img)\n",
    "        height,width = img.shape\n",
    "        # print(f'Height={height} Width={width}')\n",
    "\n",
    "        #ground truth bounding boxes\n",
    "        gt_boxes=get_boxes(row)\n",
    "\n",
    "        #get predicted bounding boxes\n",
    "        results = get_pred_bboxes(img_name, run_names, out_dir, orig_width=width, orig_height=height)\n",
    "\n",
    "        results1=dict(zip(run_names,results))   \n",
    "\n",
    "        #plot it with the b_boxes\n",
    "        uteda.plot_img_with_bboxes(img,img_name, gt_boxes,results1, size=15, show_image=show_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_IMAGES_DIR='output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see an image\n",
    "generate_images(df1, 1, TEST_DIR,OUTPUT_IMAGES_DIR, run_names=run_names, show_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all marked up images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets generate images for all the rows we predicted\n",
    "generate_images(df1, MAX_ROWS, TEST_DIR,OUTPUT_IMAGES_DIR, run_names=run_names, show_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fls=uteda.get_files(OUTPUT_IMAGES_DIR)\n",
    "\n",
    "imgs=[]\n",
    "for fle in fls:\n",
    "    img = Image.open(fle)\n",
    "    img=np.array(img)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uteda.plot_imgs(imgs, cols=2, size=20, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4a9ffdef130dccae6ae0228c0775bd6719239fc229dcdf8fb568e587357106f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "335px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "145px",
    "left": "-1.09094px",
    "right": "20px",
    "top": "543px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
